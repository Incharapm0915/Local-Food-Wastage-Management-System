{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc388e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\mjrak\\OneDrive\\Desktop\\local_food_wastage_management\n",
      "Raw data path: c:\\Users\\mjrak\\OneDrive\\Desktop\\local_food_wastage_management\\data\\raw\n",
      "Processed data path: c:\\Users\\mjrak\\OneDrive\\Desktop\\local_food_wastage_management\\data\\processed\n",
      "Raw data path exists: True\n",
      "Processed data path exists: True\n",
      "Files in raw data directory:\n",
      "  - claims_data.csv\n",
      "  - food_listings_data.csv\n",
      "  - providers_data.csv\n",
      "  - receivers_data.csv\n",
      "\n",
      "üìÇ LOADING DATA WITH CORRECT PATHS\n",
      "==================================================\n",
      "Checking CSV files:\n",
      "‚úÖ providers: providers_data.csv found\n",
      "‚úÖ receivers: receivers_data.csv found\n",
      "‚úÖ food_listings: food_listings_data.csv found\n",
      "‚úÖ claims: claims_data.csv found\n",
      "\n",
      "‚úÖ Data loaded successfully!\n",
      "Providers: 1000 records\n",
      "Receivers: 1000 records\n",
      "Food Listings: 1000 records\n",
      "Claims: 1000 records\n",
      "\n",
      "üîç FOOD LISTINGS DATA INSPECTION:\n",
      "==================================================\n",
      "Shape: (1000, 9)\n",
      "\n",
      "Columns: ['Food_ID', 'Food_Name', 'Quantity', 'Expiry_Date', 'Provider_ID', 'Provider_Type', 'Location', 'Food_Type', 'Meal_Type']\n",
      "\n",
      "Data types:\n",
      "Food_ID           int64\n",
      "Food_Name        object\n",
      "Quantity          int64\n",
      "Expiry_Date      object\n",
      "Provider_ID       int64\n",
      "Provider_Type    object\n",
      "Location         object\n",
      "Food_Type        object\n",
      "Meal_Type        object\n",
      "dtype: object\n",
      "\n",
      "First 3 rows:\n",
      "   Food_ID Food_Name  Quantity Expiry_Date  Provider_ID     Provider_Type  \\\n",
      "0        1     Bread        43   3/17/2025          110     Grocery Store   \n",
      "1        2      Soup        22   3/24/2025          791     Grocery Store   \n",
      "2        3    Fruits        46   3/28/2025          478  Catering Service   \n",
      "\n",
      "           Location       Food_Type  Meal_Type  \n",
      "0  South Kellyville  Non-Vegetarian  Breakfast  \n",
      "1        West James  Non-Vegetarian     Dinner  \n",
      "2       Lake Regina           Vegan  Breakfast  \n",
      "\n",
      "Missing values:\n",
      "Food_ID          0\n",
      "Food_Name        0\n",
      "Quantity         0\n",
      "Expiry_Date      0\n",
      "Provider_ID      0\n",
      "Provider_Type    0\n",
      "Location         0\n",
      "Food_Type        0\n",
      "Meal_Type        0\n",
      "dtype: int64\n",
      "‚úÖ Cleaning functions defined\n",
      "\n",
      "üßπ CLEANING ALL DATA\n",
      "========================================\n",
      "‚úÖ Providers cleaned: 1000 records\n",
      "‚úÖ Receivers cleaned: 1000 records\n",
      "Original food listings: 1000 records\n",
      "‚úÖ Food listings cleaned: 1000 records\n",
      "‚úÖ Claims cleaned: 1000 records\n",
      "\n",
      "üíæ SAVING CLEANED DATA\n",
      "========================================\n",
      "‚úÖ Saved providers_cleaned.csv: 1000 records\n",
      "‚úÖ Saved receivers_cleaned.csv: 1000 records\n",
      "‚úÖ Saved food_listings_cleaned.csv: 1000 records\n",
      "‚úÖ Saved claims_cleaned.csv: 1000 records\n",
      "\n",
      "üéâ ALL DATA CLEANED AND SAVED!\n",
      "üìÅ Location: c:\\Users\\mjrak\\OneDrive\\Desktop\\local_food_wastage_management\\data\\processed\n",
      "‚úÖ providers_cleaned.csv: 113,437 bytes\n",
      "‚úÖ receivers_cleaned.csv: 56,888 bytes\n",
      "‚úÖ food_listings_cleaned.csv: 73,777 bytes\n",
      "‚úÖ claims_cleaned.csv: 42,079 bytes\n",
      "\n",
      "üéØ NEXT STEPS:\n",
      "1. Run: python src/database/data_loader.py\n",
      "2. Run: python verify_setup.py\n",
      "3. All tests should now pass!\n"
     ]
    }
   ],
   "source": [
    "# FIXED PATH DATA CLEANING SCRIPT - Run in VS Code Jupyter\n",
    "# ========================================================\n",
    "# This script fixes the path issue for CSV files\n",
    "\n",
    "# Cell 1: Setup with Correct Paths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Fix path issue - go up one level from notebooks to project root\n",
    "if 'notebooks' in str(Path.cwd()):\n",
    "    project_root = Path.cwd().parent  # Go up one level from notebooks\n",
    "else:\n",
    "    project_root = Path.cwd()  # Already in project root\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Data paths - CORRECTED\n",
    "raw_data_path = project_root / \"data\" / \"raw\"\n",
    "processed_data_path = project_root / \"data\" / \"processed\"\n",
    "\n",
    "print(f\"Raw data path: {raw_data_path}\")\n",
    "print(f\"Processed data path: {processed_data_path}\")\n",
    "\n",
    "# Check if paths exist\n",
    "print(f\"Raw data path exists: {raw_data_path.exists()}\")\n",
    "print(f\"Processed data path exists: {processed_data_path.exists()}\")\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "processed_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List files in raw data directory\n",
    "if raw_data_path.exists():\n",
    "    print(f\"Files in raw data directory:\")\n",
    "    for file in raw_data_path.iterdir():\n",
    "        print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(\"‚ùå Raw data directory not found!\")\n",
    "\n",
    "# Cell 2: Load Data with Correct Paths\n",
    "print(\"\\nüìÇ LOADING DATA WITH CORRECT PATHS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define exact file paths\n",
    "csv_files = {\n",
    "    'providers': raw_data_path / \"providers_data.csv\",\n",
    "    'receivers': raw_data_path / \"receivers_data.csv\", \n",
    "    'food_listings': raw_data_path / \"food_listings_data.csv\",\n",
    "    'claims': raw_data_path / \"claims_data.csv\"\n",
    "}\n",
    "\n",
    "# Check if all files exist\n",
    "print(\"Checking CSV files:\")\n",
    "all_files_exist = True\n",
    "for name, filepath in csv_files.items():\n",
    "    if filepath.exists():\n",
    "        print(f\"‚úÖ {name}: {filepath.name} found\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: {filepath.name} NOT found\")\n",
    "        all_files_exist = False\n",
    "\n",
    "if not all_files_exist:\n",
    "    print(\"\\n‚ö†Ô∏è Some CSV files are missing!\")\n",
    "    print(\"Make sure these files are in your data/raw/ folder:\")\n",
    "    print(\"- providers_data.csv\")\n",
    "    print(\"- receivers_data.csv\") \n",
    "    print(\"- food_listings_data.csv\")\n",
    "    print(\"- claims_data.csv\")\n",
    "    \n",
    "    # Alternative: try to find files with different names\n",
    "    print(\"\\nLooking for alternative file names...\")\n",
    "    if raw_data_path.exists():\n",
    "        for file in raw_data_path.glob(\"*.csv\"):\n",
    "            print(f\"Found: {file.name}\")\n",
    "\n",
    "# Load data with error handling\n",
    "datasets = {}\n",
    "try:\n",
    "    providers_df = pd.read_csv(csv_files['providers'])\n",
    "    receivers_df = pd.read_csv(csv_files['receivers'])\n",
    "    food_listings_df = pd.read_csv(csv_files['food_listings'])\n",
    "    claims_df = pd.read_csv(csv_files['claims'])\n",
    "    \n",
    "    datasets = {\n",
    "        'providers': providers_df,\n",
    "        'receivers': receivers_df,\n",
    "        'food_listings': food_listings_df,\n",
    "        'claims': claims_df\n",
    "    }\n",
    "    \n",
    "    print(\"\\n‚úÖ Data loaded successfully!\")\n",
    "    print(f\"Providers: {len(providers_df)} records\")\n",
    "    print(f\"Receivers: {len(receivers_df)} records\")\n",
    "    print(f\"Food Listings: {len(food_listings_df)} records\")\n",
    "    print(f\"Claims: {len(claims_df)} records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading data: {e}\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"1. File names are exactly: providers_data.csv, receivers_data.csv, food_listings_data.csv, claims_data.csv\")\n",
    "    print(\"2. Files are in the data/raw/ folder\")\n",
    "    print(\"3. Files are not corrupted\")\n",
    "\n",
    "# Cell 3: Quick Data Inspection (only if data loaded successfully)\n",
    "if 'food_listings' in datasets:\n",
    "    food_listings_df = datasets['food_listings']\n",
    "    \n",
    "    print(\"\\nüîç FOOD LISTINGS DATA INSPECTION:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Shape: {food_listings_df.shape}\")\n",
    "    print(f\"\\nColumns: {list(food_listings_df.columns)}\")\n",
    "    print(f\"\\nData types:\\n{food_listings_df.dtypes}\")\n",
    "    print(f\"\\nFirst 3 rows:\")\n",
    "    print(food_listings_df.head(3))\n",
    "    print(f\"\\nMissing values:\\n{food_listings_df.isnull().sum()}\")\n",
    "\n",
    "# Cell 4: Data Cleaning Functions (same as before)\n",
    "def clean_text_column(series):\n",
    "    \"\"\"Clean text columns - remove extra spaces, handle NaN\"\"\"\n",
    "    return series.astype(str).str.strip().str.replace('nan', '').str.title()\n",
    "\n",
    "def standardize_food_type(food_type):\n",
    "    \"\"\"Standardize food type categories\"\"\"\n",
    "    if pd.isna(food_type) or str(food_type).lower() in ['nan', '', 'none']:\n",
    "        return 'Vegetarian'  # Default\n",
    "    \n",
    "    food_type = str(food_type).strip().lower()\n",
    "    \n",
    "    if 'vegan' in food_type:\n",
    "        return 'Vegan'\n",
    "    elif any(word in food_type for word in ['non-veg', 'non vegetarian', 'meat', 'chicken', 'fish', 'mutton']):\n",
    "        return 'Non-Vegetarian'\n",
    "    else:\n",
    "        return 'Vegetarian'\n",
    "\n",
    "def standardize_meal_type(meal_type):\n",
    "    \"\"\"Standardize meal type categories\"\"\"\n",
    "    if pd.isna(meal_type) or str(meal_type).lower() in ['nan', '', 'none']:\n",
    "        return 'Snacks'  # Default\n",
    "    \n",
    "    meal_type = str(meal_type).strip().lower()\n",
    "    \n",
    "    if any(word in meal_type for word in ['breakfast', 'morning']):\n",
    "        return 'Breakfast'\n",
    "    elif any(word in meal_type for word in ['lunch', 'afternoon']):\n",
    "        return 'Lunch'\n",
    "    elif any(word in meal_type for word in ['dinner', 'evening']):\n",
    "        return 'Dinner'\n",
    "    else:\n",
    "        return 'Snacks'\n",
    "\n",
    "def fix_expiry_date(date_str):\n",
    "    \"\"\"Fix and standardize expiry dates\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        parsed_date = pd.to_datetime(date_str)\n",
    "        if parsed_date.date() < datetime.now().date():\n",
    "            parsed_date = parsed_date + timedelta(days=365)\n",
    "        return parsed_date.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"‚úÖ Cleaning functions defined\")\n",
    "\n",
    "# Cell 5: Process Data (only if loaded successfully)\n",
    "if len(datasets) == 4:  # All datasets loaded\n",
    "    \n",
    "    print(\"\\nüßπ CLEANING ALL DATA\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Clean Providers\n",
    "    providers_df = datasets['providers']\n",
    "    providers_clean = providers_df.copy()\n",
    "    providers_clean['Name'] = clean_text_column(providers_clean['Name'])\n",
    "    providers_clean['Type'] = clean_text_column(providers_clean['Type'])\n",
    "    providers_clean['Address'] = clean_text_column(providers_clean['Address'])\n",
    "    providers_clean['City'] = clean_text_column(providers_clean['City'])\n",
    "    providers_clean['Contact'] = providers_clean['Contact'].astype(str)\n",
    "    providers_clean = providers_clean.drop_duplicates(subset=['Provider_ID'])\n",
    "    providers_clean = providers_clean[providers_clean['Provider_ID'] > 0]\n",
    "    \n",
    "    providers_final = providers_clean[['Provider_ID', 'Name', 'Type', 'Address', 'City', 'Contact']].copy()\n",
    "    providers_final.columns = ['provider_id', 'name', 'type', 'address', 'city', 'contact']\n",
    "    print(f\"‚úÖ Providers cleaned: {len(providers_final)} records\")\n",
    "    \n",
    "    # Clean Receivers\n",
    "    receivers_df = datasets['receivers']\n",
    "    receivers_clean = receivers_df.copy()\n",
    "    receivers_clean['Name'] = clean_text_column(receivers_clean['Name'])\n",
    "    receivers_clean['Type'] = clean_text_column(receivers_clean['Type'])\n",
    "    receivers_clean['City'] = clean_text_column(receivers_clean['City'])\n",
    "    receivers_clean['Contact'] = receivers_clean['Contact'].astype(str)\n",
    "    receivers_clean = receivers_clean.drop_duplicates(subset=['Receiver_ID'])\n",
    "    receivers_clean = receivers_clean[receivers_clean['Receiver_ID'] > 0]\n",
    "    \n",
    "    receivers_final = receivers_clean[['Receiver_ID', 'Name', 'Type', 'City', 'Contact']].copy()\n",
    "    receivers_final.columns = ['receiver_id', 'name', 'type', 'city', 'contact']\n",
    "    print(f\"‚úÖ Receivers cleaned: {len(receivers_final)} records\")\n",
    "    \n",
    "    # Clean Food Listings\n",
    "    food_listings_df = datasets['food_listings']\n",
    "    food_clean = food_listings_df.copy()\n",
    "    \n",
    "    print(f\"Original food listings: {len(food_clean)} records\")\n",
    "    \n",
    "    # Handle missing data\n",
    "    food_clean['Food_Name'] = food_clean['Food_Name'].fillna('Food Item')\n",
    "    food_clean['Food_Name'] = clean_text_column(food_clean['Food_Name'])\n",
    "    \n",
    "    food_clean['Quantity'] = pd.to_numeric(food_clean['Quantity'], errors='coerce')\n",
    "    food_clean['Quantity'] = food_clean['Quantity'].fillna(1)\n",
    "    food_clean = food_clean[food_clean['Quantity'] > 0]\n",
    "    \n",
    "    food_clean['Expiry_Date_Fixed'] = food_clean['Expiry_Date'].apply(fix_expiry_date)\n",
    "    food_clean['Food_Type_Clean'] = food_clean['Food_Type'].apply(standardize_food_type)\n",
    "    food_clean['Meal_Type_Clean'] = food_clean['Meal_Type'].apply(standardize_meal_type)\n",
    "    food_clean['Location'] = clean_text_column(food_clean['Location'])\n",
    "    food_clean['Provider_Type'] = clean_text_column(food_clean['Provider_Type'])\n",
    "    \n",
    "    # Validate Provider_IDs\n",
    "    valid_provider_ids = set(providers_final['provider_id'])\n",
    "    food_clean['Provider_ID_Valid'] = food_clean['Provider_ID'].isin(valid_provider_ids)\n",
    "    \n",
    "    if food_clean['Provider_ID_Valid'].sum() < len(food_clean) * 0.5:\n",
    "        valid_ids_list = list(valid_provider_ids)\n",
    "        def fix_provider_id(row):\n",
    "            if row['Provider_ID_Valid']:\n",
    "                return row['Provider_ID']\n",
    "            else:\n",
    "                return np.random.choice(valid_ids_list)\n",
    "        food_clean['Provider_ID_Fixed'] = food_clean.apply(fix_provider_id, axis=1)\n",
    "    else:\n",
    "        food_clean = food_clean[food_clean['Provider_ID_Valid']]\n",
    "        food_clean['Provider_ID_Fixed'] = food_clean['Provider_ID']\n",
    "    \n",
    "    food_clean = food_clean.drop_duplicates(subset=['Food_ID'])\n",
    "    \n",
    "    food_final = pd.DataFrame({\n",
    "        'food_id': food_clean['Food_ID'],\n",
    "        'food_name': food_clean['Food_Name'],\n",
    "        'quantity': food_clean['Quantity'].astype(int),\n",
    "        'expiry_date': food_clean['Expiry_Date_Fixed'],\n",
    "        'provider_id': food_clean['Provider_ID_Fixed'],\n",
    "        'provider_type': food_clean['Provider_Type'],\n",
    "        'location': food_clean['Location'],\n",
    "        'food_type': food_clean['Food_Type_Clean'],\n",
    "        'meal_type': food_clean['Meal_Type_Clean']\n",
    "    })\n",
    "    \n",
    "    food_final = food_final.dropna(subset=['food_id', 'food_name'])\n",
    "    food_final = food_final[food_final['food_id'] > 0]\n",
    "    print(f\"‚úÖ Food listings cleaned: {len(food_final)} records\")\n",
    "    \n",
    "    # Clean Claims\n",
    "    claims_df = datasets['claims']\n",
    "    claims_clean = claims_df.copy()\n",
    "    claims_clean['Timestamp'] = pd.to_datetime(claims_clean['Timestamp'], errors='coerce')\n",
    "    claims_clean = claims_clean.dropna(subset=['Timestamp'])\n",
    "    \n",
    "    status_mapping = {\n",
    "        'pending': 'Pending',\n",
    "        'completed': 'Completed', \n",
    "        'cancelled': 'Cancelled',\n",
    "        'canceled': 'Cancelled'\n",
    "    }\n",
    "    claims_clean['Status'] = claims_clean['Status'].str.lower().map(status_mapping).fillna('Pending')\n",
    "    \n",
    "    valid_food_ids = set(food_final['food_id'])\n",
    "    valid_receiver_ids = set(receivers_final['receiver_id'])\n",
    "    \n",
    "    claims_clean = claims_clean[\n",
    "        claims_clean['Food_ID'].isin(valid_food_ids) & \n",
    "        claims_clean['Receiver_ID'].isin(valid_receiver_ids)\n",
    "    ]\n",
    "    \n",
    "    claims_clean = claims_clean.drop_duplicates(subset=['Claim_ID'])\n",
    "    \n",
    "    claims_final = claims_clean[['Claim_ID', 'Food_ID', 'Receiver_ID', 'Status', 'Timestamp']].copy()\n",
    "    claims_final.columns = ['claim_id', 'food_id', 'receiver_id', 'status', 'timestamp']\n",
    "    print(f\"‚úÖ Claims cleaned: {len(claims_final)} records\")\n",
    "\n",
    "# Cell 6: Save Cleaned Data\n",
    "if len(datasets) == 4:\n",
    "    print(\"\\nüíæ SAVING CLEANED DATA\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        providers_final.to_csv(processed_data_path / 'providers_cleaned.csv', index=False)\n",
    "        print(f\"‚úÖ Saved providers_cleaned.csv: {len(providers_final)} records\")\n",
    "        \n",
    "        receivers_final.to_csv(processed_data_path / 'receivers_cleaned.csv', index=False)\n",
    "        print(f\"‚úÖ Saved receivers_cleaned.csv: {len(receivers_final)} records\")\n",
    "        \n",
    "        food_final.to_csv(processed_data_path / 'food_listings_cleaned.csv', index=False)\n",
    "        print(f\"‚úÖ Saved food_listings_cleaned.csv: {len(food_final)} records\")\n",
    "        \n",
    "        claims_final.to_csv(processed_data_path / 'claims_cleaned.csv', index=False)\n",
    "        print(f\"‚úÖ Saved claims_cleaned.csv: {len(claims_final)} records\")\n",
    "        \n",
    "        print(f\"\\nüéâ ALL DATA CLEANED AND SAVED!\")\n",
    "        print(f\"üìÅ Location: {processed_data_path}\")\n",
    "        \n",
    "        # Verify files\n",
    "        for filename in ['providers_cleaned.csv', 'receivers_cleaned.csv', 'food_listings_cleaned.csv', 'claims_cleaned.csv']:\n",
    "            filepath = processed_data_path / filename\n",
    "            if filepath.exists():\n",
    "                size = filepath.stat().st_size\n",
    "                print(f\"‚úÖ {filename}: {size:,} bytes\")\n",
    "            else:\n",
    "                print(f\"‚ùå {filename}: File not created!\")\n",
    "        \n",
    "        print(f\"\\nüéØ NEXT STEPS:\")\n",
    "        print(\"1. Run: python src/database/data_loader.py\")\n",
    "        print(\"2. Run: python verify_setup.py\")\n",
    "        print(\"3. All tests should now pass!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving files: {e}\")\n",
    "        print(f\"Processed data path: {processed_data_path}\")\n",
    "        print(f\"Path exists: {processed_data_path.exists()}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed with cleaning - data loading failed!\")\n",
    "    print(\"Please fix the CSV file paths first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
